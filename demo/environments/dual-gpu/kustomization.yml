apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

# Dual GPU deployment - deploys both llama32-1b and tinyllama-1b
# Requires 2 GPU nodes to be available
# Scale up GPU nodes: oc scale $(oc get machineset -n openshift-machine-api -o name | grep gpu) --replicas=2 -n openshift-machine-api

namespace: summit-connect-2025

resources:
  # Base includes: LlamaStack, TrustyAI, playground, shields, workbench
  - ../base
  # Model-specific resources for dual GPU
  - ../../components/inference/llama-3-2-1b
  - ../../components/inference/tinyllama-1b
  - ../../components/inference/granite-guardian-hap

# Both models deployed for testing/comparison
# Note: This requires 2 GPU nodes to avoid resource exhaustion
